{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45683,"status":"ok","timestamp":1688571980492,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"a84bdf40","outputId":"4e078002-9ef9-4ee0-fe32-afc749f9ccb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive/', force_remount=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1688571980494,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"4zbS4pALcxYd"},"outputs":[],"source":["folder_path = \"/content/gdrive/MyDrive/Voxel_Grid_classifier/\""]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3177,"status":"ok","timestamp":1688571983660,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"f42ac438"},"outputs":[],"source":["import torch\n","import os\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import torch.multiprocessing as mp\n","import gzip\n","from torch.utils.data import random_split\n","from torchsummary import summary"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1688571983661,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"MdK5RIgxmebA"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, folder_path):\n","        self.folder_path = folder_path\n","        self.file_list = os.listdir(folder_path)\n","\n","    def __len__(self):\n","        return len(self.file_list)\n","\n","    def __getitem__(self, index):\n","        file_name = self.file_list[index]\n","        file_path = os.path.join(self.folder_path, file_name)\n","        with gzip.open(file_path, 'rb') as f:\n","            loaded_data = torch.load(f, map_location=torch.device('cpu'))\n","\n","        data = loaded_data[0]\n","        label = loaded_data[1]\n","\n","        # Perform any necessary preprocessing on the data and label\n","        # ...\n","\n","        return data, label"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1688571983665,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"xWZTKEQtJ49z"},"outputs":[],"source":["class CNN3D(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CNN3D, self).__init__()\n","\n","        self.conv1 = nn.Conv3d(1, 48, kernel_size=6, stride=2, padding=1)\n","        self.relu = nn.ReLU()\n","        self.conv2 = nn.Conv3d(48, 160, kernel_size=5, stride=2)\n","        self.relu = nn.ReLU()\n","        self.conv3 = nn.Conv3d(160, 512, kernel_size=4, stride=2)\n","        self.relu = nn.ReLU()\n","        self.global_pool = nn.AdaptiveMaxPool3d((1, 1, 1))  # Global Max Pooling\n","        self.fc = nn.Linear(512, 128)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(128, num_classes)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.conv1(x))\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = self.global_pool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.relu(x)\n","        return x\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11036,"status":"ok","timestamp":1688571994677,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"G4vKgsLP217F","outputId":"0ab91871-62f4-44b7-ca83-643d38941e63"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv3d-1       [-1, 48, 99, 99, 99]          10,416\n","              ReLU-2       [-1, 48, 99, 99, 99]               0\n","            Conv3d-3      [-1, 160, 48, 48, 48]         960,160\n","              ReLU-4      [-1, 160, 48, 48, 48]               0\n","            Conv3d-5      [-1, 512, 23, 23, 23]       5,243,392\n","              ReLU-6      [-1, 512, 23, 23, 23]               0\n"," AdaptiveMaxPool3d-7         [-1, 512, 1, 1, 1]               0\n","            Linear-8                  [-1, 128]          65,664\n","              ReLU-9                  [-1, 128]               0\n","           Linear-10                   [-1, 10]           1,290\n","             ReLU-11                   [-1, 10]               0\n","================================================================\n","Total params: 6,280,922\n","Trainable params: 6,280,922\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 30.52\n","Forward/backward pass size (MB): 1075.73\n","Params size (MB): 23.96\n","Estimated Total Size (MB): 1130.21\n","----------------------------------------------------------------\n"]}],"source":["# Create an instance of the model\n","model = CNN3D(num_classes=10)\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Print the model summary to get the number of parameters\n","summary(model, (1, 200, 200, 200))  # Pass the dummy input shape directly"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":143,"status":"ok","timestamp":1688571994695,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"L4azTZtA4wrc"},"outputs":[],"source":["# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":134,"status":"ok","timestamp":1688571994699,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"njUYzA-dmzHa","outputId":"e3a6f5d8-30a9-427a-8b7c-8b3124750e15"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/gdrive/MyDrive/Voxel_Grid_classifier/'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["folder_path"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":126,"status":"ok","timestamp":1688571994701,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"zze86AgC6dRK"},"outputs":[],"source":["file_path=folder_path+ r\"/Data/Transformed_Data/Transform_1/Train_Set\"\n","file_pathtest=folder_path + r\"/Data/Transformed_Data/Transform_1/Test_Set\""]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4971,"status":"ok","timestamp":1688572018538,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"26_p9uAfK4Xs","outputId":"3eb32920-c4e0-4a90-9118-227ffc36c90c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Deleted empty file: bathtub_32.pt.gz\n","Deleted empty file: bathtub_35.pt.gz\n"]}],"source":["import os\n","\n","def remove_empty_files(folder_path):\n","    file_list = os.listdir(folder_path)\n","    for file_name in file_list:\n","        file_path = os.path.join(folder_path, file_name)\n","        if os.path.isfile(file_path) and os.path.getsize(file_path) == 0:\n","            os.remove(file_path)\n","            print(f\"Deleted empty file: {file_name}\")\n","\n","# Usage example:\n","folder_path = '/path/to/folder'\n","remove_empty_files(file_pathtest)\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":676,"status":"ok","timestamp":1688572102384,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"9ecbf992"},"outputs":[],"source":["dataset=CustomDataset(file_path)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":548,"status":"ok","timestamp":1688572107105,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"4JeLcZ7YLGS5"},"outputs":[],"source":["#Split the dataset into training and validation sets\n","train_size = int(0.85 * len(dataset))  # 80% for training, 20% for validation\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":565,"status":"ok","timestamp":1688572117852,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"4f28f842"},"outputs":[],"source":["batch_size = 20 # Adjust the batch size according to your memory capacity\n","num_workers= 8\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":757,"status":"ok","timestamp":1688572160047,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"tj0pI1j7_ZTF","outputId":"9e8b5306-96b0-43f3-c72e-ecd3d06f00e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/Voxel_Grid_classifier/ModelsPC\n"]}],"source":["%cd /content/gdrive/MyDrive/Voxel_Grid_classifier/ModelsPC"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"G6GpPDswnpz-"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Train Batch [20/134], Loss: 1.9204\n","Epoch [1/10], Train Batch [40/134], Loss: 2.0983\n","Epoch [1/10], Train Batch [60/134], Loss: 1.7790\n","Epoch [1/10], Train Batch [80/134], Loss: 2.0158\n","Epoch [1/10], Train Batch [100/134], Loss: 1.7395\n","Epoch [1/10], Train Batch [120/134], Loss: 1.9424\n","Epoch [1/10], Validation Loss: 1.8094, Validation Accuracy: 41.91%\n","Epoch [2/10], Train Batch [20/134], Loss: 1.6511\n","Epoch [2/10], Train Batch [40/134], Loss: 1.9056\n","Epoch [2/10], Train Batch [60/134], Loss: 2.0000\n","Epoch [2/10], Train Batch [80/134], Loss: 1.8500\n","Epoch [2/10], Train Batch [100/134], Loss: 1.4899\n","Epoch [2/10], Train Batch [120/134], Loss: 1.8620\n","Epoch [2/10], Validation Loss: 1.7071, Validation Accuracy: 44.26%\n","Epoch [3/10], Train Batch [20/134], Loss: 1.6494\n","Epoch [3/10], Train Batch [40/134], Loss: 1.8961\n","Epoch [3/10], Train Batch [60/134], Loss: 1.9557\n","Epoch [3/10], Train Batch [80/134], Loss: 2.0515\n","Epoch [3/10], Train Batch [100/134], Loss: 1.5080\n","Epoch [3/10], Train Batch [120/134], Loss: 1.8581\n"]}],"source":["import torch\n","\n","num_epochs = 10\n","model = model.to(device)\n","\n","# Train your model\n","train_loss = []\n","train_accuracy = []\n","val_loss = []\n","val_accuracy = []\n","\n","best_val_loss = float('inf')\n","patience = 7  # Number of epochs to wait for validation loss improvement\n","no_improvement_count = 0\n","convergence_epochs = 0\n","convergence_threshold = 0.4\n","\n","prev_val_accuracy = None  # Store previous validation accuracy\n","consecutive_equal_acc_count = 0  # Count of consecutive equal validation accuracies\n","\n","for epoch in range(num_epochs):\n","    # Training\n","    model.train()\n","    epoch_train_loss = 0\n","    epoch_train_total = 0\n","    epoch_train_correct = 0\n","\n","    for batch_idx, (data, label) in enumerate(train_dataloader):\n","        # Move the data and labels to the device\n","        data = data.to(device)\n","        label = label.to(device)\n","\n","        # Convert the data and model's weight tensor to Double\n","        data = data.unsqueeze(1)\n","        data = data.double()\n","        model.double()\n","\n","        # Forward pass\n","        outputs = model(data)\n","\n","        # Compute the loss\n","        loss = criterion(outputs, label)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_train_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        epoch_train_total += label.size(0)\n","        epoch_train_correct += (predicted == label).sum().item()\n","\n","        # Print training progress\n","        if (batch_idx + 1) % batch_size == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Train Batch [{batch_idx+1}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n","\n","    # Compute average training loss and accuracy\n","    epoch_train_loss /= len(train_dataloader)\n","    epoch_train_accuracy = 100 * epoch_train_correct / epoch_train_total\n","\n","    train_loss.append(epoch_train_loss)\n","    train_accuracy.append(epoch_train_accuracy)\n","\n","    # Validation\n","    model.eval()\n","    epoch_val_loss = 0\n","    epoch_val_total = 0\n","    epoch_val_correct = 0\n","\n","    with torch.no_grad():\n","        for data, label in val_dataloader:\n","            # Move the data and labels to the device\n","            data = data.to(device)\n","            label = label.to(device)\n","\n","            # Convert the data and model's weight tensor to Double\n","            data = data.unsqueeze(1)\n","            data = data.double()\n","            model.double()\n","\n","            # Forward pass\n","            outputs = model(data)\n","\n","            # Compute the validation loss\n","            epoch_val_loss += criterion(outputs, label).item()\n","\n","            # Compute the accuracy\n","            _, predicted = torch.max(outputs.data, 1)\n","            epoch_val_total += label.size(0)\n","            epoch_val_correct += (predicted == label).sum().item()\n","\n","    # Compute average validation loss and accuracy\n","    epoch_val_loss /= len(val_dataloader)\n","    epoch_val_accuracy = 100 * epoch_val_correct / epoch_val_total\n","\n","    val_loss.append(epoch_val_loss)\n","    val_accuracy.append(epoch_val_accuracy)\n","\n","    # Print validation results\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_accuracy:.2f}%\")\n","\n","    # Check for convergence\n","    if epoch_val_loss \u003c best_val_loss:\n","        best_val_loss = epoch_val_loss\n","        no_improvement_count = 0\n","    else:\n","        no_improvement_count += 1\n","\n","    # Check for consecutive equal validation accuracies\n","    if prev_val_accuracy is not None and epoch_val_accuracy == prev_val_accuracy:\n","        consecutive_equal_acc_count += 1\n","    else:\n","        consecutive_equal_acc_count = 0\n","\n","    prev_val_accuracy = epoch_val_accuracy\n","\n","    # Stop training if six consecutive equal validation accuracies are observed\n","    if consecutive_equal_acc_count == 6:\n","        print(\"Convergence detected: Stopping training.\")\n","        break\n","\n","torch.save(model, 'model1_200.pth')\n","torch.save(model.state_dict(), 'model1_200state.pth')\n","\n","import matplotlib.pyplot as plt\n","\n","# Plot training and validation accuracy\n","plt.figure()\n","plt.plot(train_accuracy, label='Training Accuracy')\n","plt.plot(val_accuracy, label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.show()\n","\n","# Plot training and validation loss\n","plt.figure()\n","plt.plot(train_loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":170,"status":"aborted","timestamp":1688571994773,"user":{"displayName":"Emerson Vero","userId":"00677052774200291126"},"user_tz":-120},"id":"LQSM4i8ysOCu"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPeJkKek9Pp40evAEbEUUsR","machine_shape":"hm","name":"","provenance":[{"file_id":"1SYFcgzH2O9pb9V79_Z4ZrlRNM-JMPm4D","timestamp":1688557408967},{"file_id":"1jNPV9cm9GqV3P2wmiO-eDEi_tDnLYpZO","timestamp":1686918315741}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}